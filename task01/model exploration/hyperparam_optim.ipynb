{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHJn-_QLmUYy"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aATge3n1mUY1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import typing\n",
        "from sklearn.gaussian_process.kernels import *\n",
        "import numpy as np\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Normalizer, StandardScaler, FunctionTransformer\n",
        "from scipy.optimize import minimize\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "DEBUG = True\n",
        "\n",
        "# Set `EXTENDED_EVALUATION` to `True` in order to visualize your predictions.\n",
        "EXTENDED_EVALUATION = False\n",
        "EVALUATION_GRID_POINTS = 300  # Number of grid points used in extended evaluation\n",
        "\n",
        "# Cost function constants\n",
        "COST_W_UNDERPREDICT = 50.0\n",
        "COST_W_NORMAL = 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_aQbkMUmUY4"
      },
      "source": [
        "## Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_CONFIGS = [\n",
        "    {  \n",
        "    'kernel': \n",
        "        ConstantKernel(constant_value=0.4654801542019952, constant_value_bounds=[1e-3,1e2]) \n",
        "        * Matern(length_scale=0.0668329145300999, length_scale_bounds=[1e-3, 1e1], nu=1.5) \n",
        "        + WhiteKernel(noise_level=0.0074974356622449995, noise_level_bounds=[1e-4,1e-1]),       \n",
        "    'alpha': 1e-10,\n",
        "    'normalize_y': True,\n",
        "    'n_restarts_optimizer': 0\n",
        "    },{ \n",
        "    'kernel': \n",
        "        ConstantKernel(constant_value=0.4654801542019952, constant_value_bounds=[1e-3,1e2]) \n",
        "        * Matern(length_scale=0.0668329145300999, length_scale_bounds=[1e-3, 1e1], nu=2.5) \n",
        "        + WhiteKernel(noise_level=0.0074974356622449995, noise_level_bounds=[1e-4,1e-1]),    \n",
        "    'alpha': 1e-10,\n",
        "    'normalize_y': True,\n",
        "    'n_restarts_optimizer': 0\n",
        "    },\n",
        "                ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JUBhChYImUY5"
      },
      "outputs": [],
      "source": [
        "class Model(object):\n",
        "    \"\"\"\n",
        "    Model for this task.\n",
        "    You need to implement the fit_model and predict methods\n",
        "    without changing their signatures, but are allowed to create additional methods.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, normalize_x=True, model_config={}):\n",
        "        \"\"\"\n",
        "        Initialize your model here.\n",
        "        We already provide a random number generator for reproducibility.\n",
        "        \"\"\"\n",
        "        self.rng = np.random.default_rng(seed=0)\n",
        "\n",
        "        # TODO: Add custom initialization for your model here if necessary\n",
        "\n",
        "        if normalize_x:\n",
        "            self.transformer = StandardScaler()\n",
        "        else:\n",
        "            self.transformer = FunctionTransformer(func=None, inverse_func=None, validate=True)\n",
        "        \n",
        "        self.lamda = 0\n",
        "        self.model = GaussianProcessRegressor(**model_config)\n",
        "\n",
        "    def make_predictions(self, test_x_2D: np.ndarray, test_x_AREA: np.ndarray) -> typing.Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Predict the pollution concentration for a given set of city_areas.\n",
        "        :param test_x_2D: city_areas as a 2d NumPy float array of shape (NUM_SAMPLES, 2)\n",
        "        :param test_x_AREA: city_area info for every sample in a form of a bool array (NUM_SAMPLES,)\n",
        "        :return:\n",
        "            Tuple of three 1d NumPy float arrays, each of shape (NUM_SAMPLES,),\n",
        "            containing your predictions, the GP posterior mean, and the GP posterior stddev (in that order)\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: Use your GP to estimate the posterior mean and stddev for each city_area here\n",
        "        \n",
        "        test_x = self.transformer.transform(test_x_2D)\n",
        "\n",
        "        gp_means, gp_sigmas = self.model.predict(test_x, return_std=True)\n",
        "\n",
        "        # TODO: Use the GP posterior to form your predictions here\n",
        "        predictions = gp_means\n",
        "        \n",
        "        # Adjust predictions for residential areas\n",
        "        mask = test_x_AREA\n",
        "        predictions[mask] +=  self.lamda * gp_sigmas[mask]\n",
        "\n",
        "        return predictions, gp_means, gp_sigmas\n",
        "    \n",
        "    def get_mean_variance(self, test_x_2D: np.ndarray) -> typing.Tuple[np.ndarray, np.ndarray, np.ndarray]: \n",
        "        gp_means, gp_sigmas = self.model.predict(test_x_2D, return_std=True)\n",
        "        return gp_means, gp_sigmas\n",
        "\n",
        "    def fitting_model(self, train_y: np.ndarray, train_x_2D: np.ndarray, fit_lamda: bool = True):\n",
        "        \"\"\"\n",
        "        Fit your model on the given training data.\n",
        "        :param train_x_2D: Training features as a 2d NumPy float array of shape (NUM_SAMPLES, 2)\n",
        "        :param train_y: Training pollution concentrations as a 1d NumPy float array of shape (NUM_SAMPLES,)\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: Fit your model here\n",
        "\n",
        "        self.transformer = self.transformer.fit(train_x_2D)\n",
        "        train_x = self.transformer.transform(train_x_2D)\n",
        "\n",
        "        self.model = self.model.fit(train_x, train_y)\n",
        "        \n",
        "        if fit_lamda:\n",
        "            means, sigmas = self.get_mean_variance(train_x)\n",
        "            initial_lambda = 1\n",
        "            self.lamda = minimize(lambda_cost_function, initial_lambda, args=(means, sigmas, train_y)).x[0]\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2h2nwBQVmUY6"
      },
      "outputs": [],
      "source": [
        "# You don't have to change this function\n",
        "def cost_function(ground_truth: np.ndarray, predictions: np.ndarray, AREA_idxs: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Calculates the cost of a set of predictions.\n",
        "\n",
        "    :param ground_truth: Ground truth pollution levels as a 1d NumPy float array\n",
        "    :param predictions: Predicted pollution levels as a 1d NumPy float array\n",
        "    :param AREA_idxs: city_area info for every sample in a form of a bool array (NUM_SAMPLES,)\n",
        "    :return: Total cost of all predictions as a single float\n",
        "    \"\"\"\n",
        "    assert ground_truth.ndim == 1 and predictions.ndim == 1 and ground_truth.shape == predictions.shape\n",
        "\n",
        "    # Unweighted cost\n",
        "    cost = (ground_truth - predictions) ** 2\n",
        "    weights = np.ones_like(cost) * COST_W_NORMAL\n",
        "\n",
        "    # Case i): underprediction\n",
        "    mask = (predictions < ground_truth) & [bool(AREA_idx) for AREA_idx in AREA_idxs]\n",
        "    weights[mask] = COST_W_UNDERPREDICT\n",
        "\n",
        "    # Weigh the cost and return the average\n",
        "    return np.mean(cost * weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lambda_cost_function(lambda_val, mu_values, sigma_values, y_true_values):\n",
        "    \"\"\"\n",
        "    Calculates the cost of predictions for a given lambda value.\n",
        "\n",
        "    :param lambda_val: Value of lambda to compute predictions\n",
        "    :param mu_values: Predicted mean values (mu)\n",
        "    :param sigma_values: Predicted standard deviation values (sigma)\n",
        "    :param y_true_values: Ground truth values\n",
        "    :return: Total cost for the given lambda value\n",
        "    \"\"\"\n",
        "    \n",
        "    # Compute predictions for the given lambda value\n",
        "    predictions = mu_values + lambda_val * sigma_values\n",
        "    \n",
        "    # Use the provided cost function to compute the cost\n",
        "    cost = cost_function(y_true_values, predictions, np.ones_like(y_true_values, dtype=bool))\n",
        "    \n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rnnQZhHcmUY6"
      },
      "outputs": [],
      "source": [
        "# You don't have to change this function\n",
        "def is_in_circle(coor, circle_coor):\n",
        "    \"\"\"\n",
        "    Checks if a coordinate is inside a circle.\n",
        "    :param coor: 2D coordinate\n",
        "    :param circle_coor: 3D coordinate of the circle center and its radius\n",
        "    :return: True if the coordinate is inside the circle, False otherwise\n",
        "    \"\"\"\n",
        "    return (coor[0] - circle_coor[0])**2 + (coor[1] - circle_coor[1])**2 < circle_coor[2]**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9FB9GGCvmUY7"
      },
      "outputs": [],
      "source": [
        "# You don't have to change this function\n",
        "def determine_city_area_idx(visualization_xs_2D):\n",
        "    \"\"\"\n",
        "    Determines the city_area index for each coordinate in the visualization grid.\n",
        "    :param visualization_xs_2D: 2D coordinates of the visualization grid\n",
        "    :return: 1D array of city_area indexes\n",
        "    \"\"\"\n",
        "    # Circles coordinates\n",
        "    circles = np.array([[0.5488135, 0.71518937, 0.17167342],\n",
        "                    [0.79915856, 0.46147936, 0.1567626 ],\n",
        "                    [0.26455561, 0.77423369, 0.10298338],\n",
        "                    [0.6976312,  0.06022547, 0.04015634],\n",
        "                    [0.31542835, 0.36371077, 0.17985623],\n",
        "                    [0.15896958, 0.11037514, 0.07244247],\n",
        "                    [0.82099323, 0.09710128, 0.08136552],\n",
        "                    [0.41426299, 0.0641475,  0.04442035],\n",
        "                    [0.09394051, 0.5759465,  0.08729856],\n",
        "                    [0.84640867, 0.69947928, 0.04568374],\n",
        "                    [0.23789282, 0.934214,   0.04039037],\n",
        "                    [0.82076712, 0.90884372, 0.07434012],\n",
        "                    [0.09961493, 0.94530153, 0.04755969],\n",
        "                    [0.88172021, 0.2724369,  0.04483477],\n",
        "                    [0.9425836,  0.6339977,  0.04979664]])\n",
        "\n",
        "    visualization_xs_AREA = np.zeros((visualization_xs_2D.shape[0],))\n",
        "\n",
        "    for i,coor in enumerate(visualization_xs_2D):\n",
        "        visualization_xs_AREA[i] = any([is_in_circle(coor, circ) for circ in circles])\n",
        "\n",
        "    return visualization_xs_AREA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Frrw1pZkmUY7"
      },
      "outputs": [],
      "source": [
        "# You don't have to change this function\n",
        "def perform_extended_evaluation(model: Model, output_dir: str = '/results'):\n",
        "    \"\"\"\n",
        "    Visualizes the predictions of a fitted model.\n",
        "    :param model: Fitted model to be visualized\n",
        "    :param output_dir: Directory in which the visualizations will be stored\n",
        "    \"\"\"\n",
        "    print('Performing extended evaluation')\n",
        "\n",
        "    # Visualize on a uniform grid over the entire coordinate system\n",
        "    grid_lat, grid_lon = np.meshgrid(\n",
        "        np.linspace(0, EVALUATION_GRID_POINTS - 1, num=EVALUATION_GRID_POINTS) / EVALUATION_GRID_POINTS,\n",
        "        np.linspace(0, EVALUATION_GRID_POINTS - 1, num=EVALUATION_GRID_POINTS) / EVALUATION_GRID_POINTS,\n",
        "    )\n",
        "    visualization_xs_2D = np.stack((grid_lon.flatten(), grid_lat.flatten()), axis=1)\n",
        "    visualization_xs_AREA = determine_city_area_idx(visualization_xs_2D)\n",
        "\n",
        "    # Obtain predictions, means, and stddevs over the entire map\n",
        "    predictions, gp_mean, gp_stddev = model.make_predictions(visualization_xs_2D, visualization_xs_AREA)\n",
        "    predictions = np.reshape(predictions, (EVALUATION_GRID_POINTS, EVALUATION_GRID_POINTS))\n",
        "    gp_mean = np.reshape(gp_mean, (EVALUATION_GRID_POINTS, EVALUATION_GRID_POINTS))\n",
        "\n",
        "    vmin, vmax = 0.0, 65.0\n",
        "\n",
        "    # Plot the actual predictions\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_title('Extended visualization of task 1')\n",
        "    im = ax.imshow(predictions, vmin=vmin, vmax=vmax)\n",
        "    cbar = fig.colorbar(im, ax = ax)\n",
        "\n",
        "    # Save figure to pdf\n",
        "    figure_path = os.path.join(output_dir, 'extended_evaluation.pdf')\n",
        "    fig.savefig(figure_path)\n",
        "    print(f'Saved extended evaluation to {figure_path}')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vIMcoLk8mUY-"
      },
      "outputs": [],
      "source": [
        "def extract_city_area_information(train_x: np.ndarray, test_x: np.ndarray) -> typing.Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Extracts the city_area information from the training and test features.\n",
        "    :param train_x: Training features\n",
        "    :param test_x: Test features\n",
        "    :return: Tuple of (training features' 2D coordinates, training features' city_area information,\n",
        "        test features' 2D coordinates, test features' city_area information)\n",
        "    \"\"\"\n",
        "\n",
        "    #TODO: Extract the city_area information from the training and test features\n",
        "    train_x_2D = np.array(train_x[:, :2], dtype=float)\n",
        "    train_x_AREA = np.array(train_x[:, 2], dtype=bool)\n",
        "    test_x_2D = np.array(test_x[:, :2], dtype=float)\n",
        "    test_x_AREA = np.array(test_x[:, 2], dtype=bool)\n",
        "\n",
        "    assert train_x_2D.shape[0] == train_x_AREA.shape[0] and test_x_2D.shape[0] == test_x_AREA.shape[0]\n",
        "    assert train_x_2D.shape[1] == 2 and test_x_2D.shape[1] == 2\n",
        "    assert train_x_AREA.ndim == 1 and test_x_AREA.ndim == 1\n",
        "\n",
        "    return train_x_2D, train_x_AREA, test_x_2D, test_x_AREA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LmL0HspmUZA"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANVuUY9GmUZA",
        "outputId": "4f34baa7-6f54-436e-ddde-cdcd7d54ea76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of train_x_2D: (15189, 2)\n",
            "Shape of train_x_AREA: (15189,)\n",
            "Shape of test_x_2D: (3311, 2)\n",
            "Shape of test_x_AREA: (3311,)\n"
          ]
        }
      ],
      "source": [
        "train_x = np.loadtxt('../train_x.csv', delimiter=',', skiprows=1)\n",
        "train_y = np.loadtxt('../train_y.csv', delimiter=',', skiprows=1)\n",
        "test_x = np.loadtxt('../test_x.csv', delimiter=',', skiprows=1)\n",
        "\n",
        "train_x_2D, train_x_AREA, test_x_2D, test_x_AREA = extract_city_area_information(train_x, test_x)\n",
        "\n",
        "if DEBUG:\n",
        "    print(f\"Shape of train_x_2D: {train_x_2D.shape}\")\n",
        "    print(f\"Shape of train_x_AREA: {train_x_AREA.shape}\")\n",
        "    print(f\"Shape of test_x_2D: {test_x_2D.shape}\")\n",
        "    print(f\"Shape of test_x_AREA: {test_x_AREA.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train-Val Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of train_x_2D_train: (15181, 2)\n",
            "Shape of train_x_AREA_train: (15181,)\n",
            "Shape of train_y_train: (15181,)\n",
            "Shape of train_x_2D_val: (8, 2)\n",
            "Shape of train_x_AREA_val: (8,)\n",
            "Shape of train_y_val: (8,)\n"
          ]
        }
      ],
      "source": [
        "train_x_2D_train, train_x_2D_val, train_x_AREA_train, train_x_AREA_val, train_y_train, train_y_val = train_test_split(\n",
        "    train_x_2D, train_x_AREA, train_y, test_size=0.0005, random_state=7\n",
        ")\n",
        "\n",
        "if DEBUG:\n",
        "    print(f\"Shape of train_x_2D_train: {train_x_2D_train.shape}\")\n",
        "    print(f\"Shape of train_x_AREA_train: {train_x_AREA_train.shape}\")\n",
        "    print(f\"Shape of train_y_train: {train_y_train.shape}\")\n",
        "    print(f\"Shape of train_x_2D_val: {train_x_2D_val.shape}\")\n",
        "    print(f\"Shape of train_x_AREA_val: {train_x_AREA_val.shape}\")\n",
        "    print(f\"Shape of train_y_val: {train_y_val.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.04**2 * Matern(length_scale=0.202, nu=1.5) + WhiteKernel(noise_level=0.00535)\n",
            "{'k1': 1.04**2 * Matern(length_scale=0.202, nu=1.5), 'k2': WhiteKernel(noise_level=0.00535), 'k1__k1': 1.04**2, 'k1__k2': Matern(length_scale=0.202, nu=1.5), 'k1__k1__constant_value': 1.078650707257617, 'k1__k1__constant_value_bounds': [0.001, 100.0], 'k1__k2__length_scale': 0.20164570436472332, 'k1__k2__length_scale_bounds': [0.001, 10.0], 'k1__k2__nu': 1.5, 'k2__noise_level': 0.005346546582467515, 'k2__noise_level_bounds': [0.0001, 0.1]}\n",
            "Optimal lamda = 1.047\n",
            "R^2 score for the training set: 0.9967\n",
            "R^2 score for the validation set: 0.9954\n",
            "Cost for the training set: 3.2598\n",
            "Cost for the validation set: 5.3771\n",
            "\n",
            "0.835**2 * Matern(length_scale=0.122, nu=2.5) + WhiteKernel(noise_level=0.00613)\n",
            "{'k1': 0.835**2 * Matern(length_scale=0.122, nu=2.5), 'k2': WhiteKernel(noise_level=0.00613), 'k1__k1': 0.835**2, 'k1__k2': Matern(length_scale=0.122, nu=2.5), 'k1__k1__constant_value': 0.6974382851073578, 'k1__k1__constant_value_bounds': [0.001, 100.0], 'k1__k2__length_scale': 0.1215927451462286, 'k1__k2__length_scale_bounds': [0.001, 10.0], 'k1__k2__nu': 2.5, 'k2__noise_level': 0.006128574524720481, 'k2__noise_level_bounds': [0.0001, 0.1]}\n",
            "Optimal lamda = 1.147\n",
            "R^2 score for the training set: 0.9957\n",
            "R^2 score for the validation set: 0.9948\n",
            "Cost for the training set: 4.2483\n",
            "Cost for the validation set: 6.1867\n",
            "\n"
          ]
        }
      ],
      "source": [
        "models = []\n",
        "for config in MODEL_CONFIGS:\n",
        "    model = Model(normalize_x=True, model_config=config)\n",
        "    model.fitting_model(train_y_train, train_x_2D_train, fit_lamda=True)\n",
        "    models.append(model)\n",
        "    print(model.model.kernel_)\n",
        "    print(model.model.kernel_.get_params())\n",
        "    print(f\"Optimal lamda = {model.lamda:.3f}\")\n",
        "    train_score = model.model.score(model.transformer.transform(train_x_2D_train), train_y_train)\n",
        "    val_score = model.model.score(model.transformer.transform(train_x_2D_val), train_y_val)\n",
        "    print(f\"R^2 score for the training set: {train_score:.4f}\")\n",
        "    print(f\"R^2 score for the validation set: {val_score:.4f}\")\n",
        "    train_predictions = model.make_predictions(train_x_2D_train, train_x_AREA_train)\n",
        "    val_predictions = model.make_predictions(train_x_2D_val, train_x_AREA_val)\n",
        "    test_predictions = model.make_predictions(test_x_2D, test_x_AREA)\n",
        "    train_cost = cost_function(train_y_train, train_predictions[0], train_x_AREA_train)\n",
        "    val_cost = cost_function(train_y_val, val_predictions[0], train_x_AREA_val)\n",
        "    print(f\"Cost for the training set: {train_cost:.4f}\")\n",
        "    print(f\"Cost for the validation set: {val_cost:.4f}\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "9LmL0HspmUZA",
        "DwBvaDB1mUZC"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
